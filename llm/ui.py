"""
æ¨¡å—åŒ–çš„ Gradio UIï¼ˆè¿ç§»è‡ªå•æ–‡ä»¶ app.pyï¼‰
ä¾èµ–ï¼šllm.config, llm.state, llm.models, llm.convos, llm.tokenizer, llm.generation, llm.utils
æ‰€æœ‰ handler è¿”å›åŸºç¡€æ•°æ®æˆ– gr.updateï¼Œä»¥ä¾¿æµ‹è¯•å’Œ UI å±‚åˆ†ç¦»ã€‚
"""

import gradio as gr
from typing import List, Tuple, Optional
from . import convos, models, tokenizer as tkmod, generation, utils
from .state import state
from .config import CONFIG
from .utils import clean_text, truncate_text
from .convos import get_conversation_dropdown_options, get_conversation_history
from .models import load_model, unload_model
from .generation import chat_stream, stop_generation
from datetime import datetime
import json
import tempfile
import logging

logger = logging.getLogger(__name__)

# System and stats HTML renderers are ported from app.py for UI convenience.
def get_system_info_html(get_system_info_fn):
    """Wrap to generate HTML (get_system_info_fn is passed from main to keep separation)"""
    system_info = get_system_info_fn()
    # Small version of the original HTML generator for system info
    html = f"""
    <div style="background: linear-gradient(135deg,#4facfe 0%, #00f2fe 100%); color: white; padding: 12px; border-radius: 10px;">
      <h3 style="margin-top:0;">ğŸ’» ç³»ç»Ÿç›‘æ§</h3>
      <div>CPU: {system_info.get('cpu_usage', 0):.1f}%</div>
      <div>å†…å­˜: {system_info.get('memory_usage', 0):.1f}%</div>
      <div>ç£ç›˜: {system_info.get('disk_usage', 0):.1f}%</div>
    """
    if system_info.get('cuda_available', False):
        html += f"<div>GPU: {system_info.get('torch_gpu_name','æœªçŸ¥')} | æ˜¾å­˜: {system_info.get('torch_gpu_memory_allocated', 0):.2f}G</div>"
    else:
        html += "<div style='color: #ff6b6b;'>âš ï¸ CUDAä¸å¯ç”¨ï¼Œæ¨¡å‹è¿è¡Œåœ¨CPUä¸Š</div>"
    html += "</div>"
    return html

def get_stats_html(get_stats_fn):
    st = get_stats_fn()
    run_time = datetime.now() - st['start_time']
    minutes = int(run_time.total_seconds() // 60)
    avg_time = st['total_time'] / max(1, st['total_requests'])
    html = f"""
    <div style="padding:12px;border-radius:10px;background:linear-gradient(135deg,#f093fb 0,#f5576c 100%);color:white;">
      <div>è¯·æ±‚æ•°: {st['total_requests']}</div>
      <div>Tokenæ•°: {st['total_tokens']}</div>
      <div>å¹³å‡å“åº”: {avg_time:.2f}s</div>
      <div>è¿è¡Œ: {minutes}m</div>
    </div>
    """
    return html


def create_interface(get_system_info_fn=None, get_stats_fn=None):
    """
    å»ºç«‹å®Œæ•´ Gradio ç•Œé¢ï¼Œç±»ä¼¼åŸå§‹ app.py çš„ UI åŠäº‹ä»¶ç»‘å®šã€‚
    get_system_info_fn & get_stats_fn æ˜¯å¯æ³¨å…¥å›è°ƒï¼ˆç”¨äºæµ‹è¯•æˆ–æ¨¡å—åŒ–ï¼‰
    """
    # default callbacks if not provided (keep minimal)
    if get_system_info_fn is None:
        from . import utils as _u
        get_system_info_fn = lambda: {}  # minimal; main.py will pass real functions
    if get_stats_fn is None:
        get_stats_fn = lambda: state.stats

    with gr.Blocks(
        theme=gr.themes.Soft(primary_hue="blue", secondary_hue="slate"),
        title="å¤§æ¨¡å‹å¯¹è¯ç³»ç»Ÿ",
        css="""
        .gradio-container { max-width: 95% !important; }
        .conversation-item { padding: 8px 12px; margin: 2px 0; border-radius: 6px; cursor: pointer; }
        .conversation-item:hover { background: rgba(0,0,0,0.05); }
        .conversation-active { background: rgba(59,130,246,0.1); border-left: 3px solid #3b82f6; }
        """
    ) as demo:

        gr.Markdown("# ğŸ¤– å¤§æ¨¡å‹å¯¹è¯ç³»ç»Ÿ\n**æ¨¡å—åŒ– UIï¼ˆè¿ç§»ï¼‰**")

        # åˆå§‹é€‰æ‹©åˆ—è¡¨
        conv_options = get_conversation_dropdown_options()
        conversation_value = state.current_conversation_id or (conv_options[0][1] if conv_options else "")

        # left column control panel
        with gr.Row():
            with gr.Column(scale=1, min_width=320):
                gr.Markdown("### ğŸ’¬ å¯¹è¯ç®¡ç†")
                with gr.Row():
                    new_convo_btn = gr.Button("ğŸ†• æ–°å»ºå¯¹è¯", variant="primary", size="sm")
                    refresh_convos_btn = gr.Button("ğŸ”„ åˆ·æ–°", variant="secondary", size="sm")
                conversation_dropdown = gr.Dropdown(choices=conv_options, value=conversation_value, label="é€‰æ‹©å¯¹è¯", interactive=True, filterable=True)
                conversation_state = gr.State(state.current_conversation_id)

                with gr.Row():
                    delete_convo_btn = gr.Button("ğŸ—‘ï¸ åˆ é™¤å¯¹è¯", variant="stop", size="sm")
                    export_convo_btn = gr.Button("ğŸ“¤ å¯¼å‡ºå¯¹è¯", variant="secondary", size="sm")

                gr.Markdown("### ğŸš€ æ¨¡å‹æ§åˆ¶")
                model_dropdown = gr.Dropdown(choices=list(models.MODEL_PATHS.keys()), value=state.current_model or (list(models.MODEL_PATHS.keys())[0] if models.MODEL_PATHS else ""), label="é€‰æ‹©æ¨¡å‹", filterable=True)
                with gr.Row():
                    load_btn = gr.Button("ğŸ”„ åŠ è½½æ¨¡å‹", variant="primary")
                    unload_btn = gr.Button("ğŸ—‘ï¸ å¸è½½æ¨¡å‹", variant="secondary")
                load_status = gr.Markdown("ğŸ‘† è¯·é€‰æ‹©å¹¶åŠ è½½æ¨¡å‹")
                model_info_html = gr.HTML()

                with gr.Accordion("ğŸ”§ æ¨¡å‹ç®¡ç†", open=False):
                    new_model_name = gr.Textbox(label="æ¨¡å‹åç§°", placeholder="æ˜¾ç¤ºåç§°")
                    new_model_path = gr.Textbox(label="æ¨¡å‹è·¯å¾„", placeholder="æœ¬åœ°è·¯å¾„")
                    with gr.Row():
                        add_model_btn = gr.Button("â• æ·»åŠ æ¨¡å‹")
                        remove_model_btn = gr.Button("â– ç§»é™¤æ¨¡å‹")

                gr.Markdown("### âš™ï¸ ç”Ÿæˆå‚æ•°")
                max_new_tokens = gr.Slider(512, 8192, value=state.current_params['max_new_tokens'], step=256, label="ç”Ÿæˆé•¿åº¦")
                temperature = gr.Slider(0.1, 2.0, value=state.current_params['temperature'], step=0.1, label="æ¸©åº¦")
                top_p = gr.Slider(0.1, 1.0, value=state.current_params['top_p'], step=0.1, label="Top-P")
                top_k = gr.Slider(1, 100, value=state.current_params['top_k'], step=1, label="Top-K")
                repetition_penalty = gr.Slider(1.0, 2.0, value=state.current_params['repetition_penalty'], step=0.1, label="é‡å¤æƒ©ç½š")
                max_history_slider = gr.Slider(1, 50, value=state.current_params['max_history'], step=1, label="å¯¹è¯è®°å¿†è½®æ•°")
                do_sample = gr.Checkbox(value=state.current_params['do_sample'], label="éšæœºé‡‡æ ·")
                with gr.Row():
                    update_btn = gr.Button("ğŸ’¾ ä¿å­˜å‚æ•°", variant="primary")
                    reset_btn = gr.Button("ğŸ”„ é‡ç½®é»˜è®¤", variant="secondary")
                param_status = gr.Markdown("âœ… å‚æ•°å·²å°±ç»ª")

                gr.Markdown("### ğŸ“Š ç³»ç»Ÿä¸ç»Ÿè®¡")
                with gr.Row():
                    refresh_sys_btn = gr.Button("ğŸ”„ åˆ·æ–°çŠ¶æ€", variant="secondary", size="sm")
                    stop_btn = gr.Button("â¹ï¸ åœæ­¢ç”Ÿæˆ", variant="stop", size="sm")
                    clean_memory_btn = gr.Button("ğŸ§¹ æ¸…ç†å†…å­˜", variant="secondary", size="sm")
                system_html = gr.HTML(get_system_info_html(get_system_info_fn))
                stats_html = gr.HTML(get_stats_html(get_stats_fn))

            # right column chat area
            with gr.Column(scale=2, min_width=600):
                current_conv_md = gr.Markdown(lambda: convos.get_current_conversation_info() if hasattr(convos, 'get_current_conversation_info') else "å½“å‰å¯¹è¯")
                chatbot = gr.Chatbot(value=get_conversation_history(state.current_conversation_id), label="ğŸ’¬ æ™ºèƒ½å¯¹è¯", height=520, type="tuples", show_copy_button=True)
                with gr.Row():
                    msg_box = gr.Textbox(placeholder="è¯·è¾“å…¥é—®é¢˜ï¼ŒæŒ‰Enterå‘é€", lines=2, max_lines=5, show_label=False)
                    send_btn = gr.Button("ğŸš€ å‘é€")
                # quick buttons
                with gr.Row():
                    quick_clear = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå½“å‰")
                    quick_example1 = gr.Button("ğŸ‘‹ æ‰“ä¸ªæ‹›å‘¼")
                    quick_example2 = gr.Button("ğŸ“ å†™æ®µä»£ç ")
                    quick_example3 = gr.Button("ğŸ¤” è§£é‡Šæ¦‚å¿µ")

                message_counter = gr.HTML(lambda: f"å½“å‰å¯¹è¯: {len(convos.get_conversation_history(state.current_conversation_id))//2} æ¡æ¶ˆæ¯")

        # ---------- handlers ----------
        def handle_load_model(model_name: str):
            if not model_name:
                return "âŒ è¯·é€‰æ‹©æ¨¡å‹", "", get_stats_html(get_stats_fn), get_system_info_html(get_system_info_fn)
            if model_name not in models.MODEL_PATHS:
                return "âŒ æ¨¡å‹è·¯å¾„ä¸å¯ç”¨", "", get_stats_html(get_stats_fn), get_system_info_html(get_system_info_fn)
            result, info_html = load_model(models.MODEL_PATHS[model_name], model_name)
            return result, info_html, get_stats_html(get_stats_fn), get_system_info_html(get_system_info_fn)

        def handle_unload_model():
            result, info_html = unload_model()
            return result, info_html, get_stats_html(get_stats_fn), get_system_info_html(get_system_info_fn)

        def handle_send(message: str, conversation_id: str):
            # Streaming generator - adapted to gradio's streaming expectations
            if not message.strip():
                yield get_conversation_history(conversation_id), get_stats_html(get_stats_fn), get_system_info_html(get_system_info_fn), "", convos.get_current_conversation_info()
                return
            for history, stats_html, system_html in chat_stream(message, conversation_id):
                # stats_html and system_html are placeholders - UI uses our renderers
                yield history, get_stats_html(get_stats_fn), get_system_info_html(get_system_info_fn), "", convos.get_current_conversation_info()

        def handle_new_conversation():
            new_id = convos.create_new_conversation("æ–°å¯¹è¯")
            cfg = json.loads(json.dumps({"last_conversation": new_id}))  # light update; real save uses config module
            # update dropdown choices
            opts = convos.get_conversation_dropdown_options()
            return gr.update(choices=opts, value=new_id), convos.get_conversation_history(new_id), convos.get_current_conversation_info(), new_id

        def handle_refresh_conversations():
            convos.load_conversations()
            opts = convos.get_conversation_dropdown_options()
            cur = state.current_conversation_id or (opts[0][1] if opts else "")
            return gr.update(choices=opts, value=cur)

        def handle_conversation_change(conv_id: str):
            if conv_id and conv_id in state.conversations:
                state.current_conversation_id = conv_id
                # persist selection
                # config.save_config(...) -- main app should call this
                return convos.get_conversation_history(conv_id), convos.get_current_conversation_info(), conv_id
            return gr.update(), gr.update(), state.current_conversation_id

        def handle_delete_conversation(conv_id: str):
            if not conv_id:
                return gr.update(), gr.update(), gr.update(), gr.update(), "âŒ åˆ é™¤å¤±è´¥"
            success = convos.delete_conversation(conv_id)
            if success:
                opts = convos.get_conversation_dropdown_options()
                current_value = state.current_conversation_id or (opts[0][1] if opts else "")
                history = convos.get_conversation_history(state.current_conversation_id) if state.current_conversation_id else []
                return gr.update(choices=opts, value=current_value), history, convos.get_current_conversation_info(), state.current_conversation_id, "âœ… å¯¹è¯å·²åˆ é™¤"
            return gr.update(), gr.update(), gr.update(), gr.update(), "âŒ åˆ é™¤å¤±è´¥"

        def handle_export_conversation(conv_id: str):
            if not conv_id or conv_id not in state.conversations:
                return gr.update(value=None), "", "âŒ å¯¼å‡ºå¤±è´¥"
            convo = state.conversations[conv_id]
            export_data = {"title": convo["title"], "created_at": convo["created_at"], "messages": convo["messages"], "model_used": convo.get("model_used","æœªçŸ¥")}
            export_str = json.dumps(export_data, ensure_ascii=False, indent=2)
            tf = tempfile.NamedTemporaryFile(delete=False, suffix=".json", mode="w", encoding="utf-8")
            tf.write(export_str); tf.flush(); tf.close()
            filename = f"{convo['title']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            return gr.update(value=tf.name), filename, "âœ… å¯¼å‡ºæˆåŠŸ"

        def handle_clear_current_conversation(conv_id: str):
            if not conv_id or conv_id not in state.conversations:
                return [], convos.get_current_conversation_info()
            state.conversations[conv_id]["messages"] = []
            convos.save_conversation(conv_id)
            return [], convos.get_current_conversation_info()

        def handle_quick_example(kind: str):
            examples = {
                "greeting": "ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚",
                "code": "è¯·ç”¨Pythonå†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•ï¼Œå¹¶æ·»åŠ è¯¦ç»†æ³¨é‡Šã€‚",
                "explain": "è¯·ç”¨é€šä¿—æ˜“æ‡‚çš„æ–¹å¼è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ã€‚"
            }
            return examples.get(kind, "ä½ å¥½ï¼")

        # bind events
        load_btn.click(fn=handle_load_model, inputs=[model_dropdown], outputs=[load_status, model_info_html, stats_html, system_html])
        unload_btn.click(fn=handle_unload_model, outputs=[load_status, model_info_html, stats_html, system_html])
        send_event = msg_box.submit(fn=handle_send, inputs=[msg_box, conversation_state], outputs=[chatbot, stats_html, system_html, msg_box, current_conv_md])
        send_btn.click(fn=handle_send, inputs=[msg_box, conversation_state], outputs=[chatbot, stats_html, system_html, msg_box, current_conv_md])
        new_convo_btn.click(fn=handle_new_conversation, outputs=[conversation_dropdown, chatbot, current_conv_md, conversation_state])
        refresh_convos_btn.click(fn=handle_refresh_conversations, outputs=[conversation_dropdown])
        conversation_dropdown.change(fn=handle_conversation_change, inputs=[conversation_dropdown], outputs=[chatbot, current_conv_md, conversation_state])
        delete_convo_btn.click(fn=lambda: handle_delete_conversation(state.current_conversation_id), outputs=[conversation_dropdown, chatbot, current_conv_md, conversation_state, load_status])
        export_convo_btn.click(fn=lambda: handle_export_conversation(state.current_conversation_id), outputs=[gr.File(), gr.Textbox(), load_status])
        quick_clear.click(fn=lambda: handle_clear_current_conversation(state.current_conversation_id), outputs=[chatbot, current_conv_md])
        quick_example1.click(fn=lambda: handle_quick_example("greeting"), outputs=[msg_box])
        quick_example2.click(fn=lambda: handle_quick_example("code"), outputs=[msg_box])
        quick_example3.click(fn=lambda: handle_quick_example("explain"), outputs=[msg_box])
        refresh_sys_btn.click(fn=lambda: [get_system_info_html(get_system_info_fn), get_stats_html(get_stats_fn)], outputs=[system_html, stats_html])
        stop_btn.click(fn=stop_generation, outputs=[load_status])
        clean_memory_btn.click(fn=models.unload_model, outputs=[load_status])  # reuse unload to ~free
        add_model_btn.click(fn=models.add_model_path, inputs=[new_model_name, new_model_path], outputs=[load_status, model_dropdown])
        remove_model_btn.click(fn=models.remove_model_path, inputs=[model_dropdown], outputs=[load_status, model_dropdown])
        update_btn.click(fn=lambda a,b,c,d,e,f,g: update_and_report(a,b,c,d,e,f,g), inputs=[max_new_tokens, temperature, top_p, repetition_penalty, max_history_slider, top_k, do_sample], outputs=[param_status])
        reset_btn.click(fn=lambda: reset_and_report(), outputs=[max_new_tokens, temperature, top_p, repetition_penalty, max_history_slider, top_k, do_sample, param_status])

    return demo

# helper for param update/reset (keeps state centrally)
def update_and_report(max_new_tokens, temperature, top_p, repetition_penalty, max_history, top_k, do_sample):
    state.current_params.update({
        'max_new_tokens': max_new_tokens,
        'temperature': temperature,
        'top_p': top_p,
        'repetition_penalty': repetition_penalty,
        'max_history': max_history,
        'top_k': top_k,
        'do_sample': do_sample
    })
    return f"âœ… å‚æ•°å·²æ›´æ–° | é•¿åº¦: {max_new_tokens} | æ¸©åº¦: {temperature}"

def reset_and_report():
    state.current_params = state.default_params.copy()
    return (
        state.default_params['max_new_tokens'],
        state.default_params['temperature'],
        state.default_params['top_p'],
        state.default_params['repetition_penalty'],
        state.default_params['max_history'],
        state.default_params.get('top_k', 50),
        state.default_params.get('do_sample', True),
        "âœ… å‚æ•°å·²é‡ç½®ä¸ºé»˜è®¤å€¼"
    )